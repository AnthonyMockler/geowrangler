{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4460eac-f6b8-4d46-b971-109ed6ba24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.ookla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f3485c-20cb-44c9-a82d-3cef6a4047cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# no_test\n",
    "![ -e /content ] && pip install -Uqq geowrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ad1a2-b0df-4675-af9e-3223c8f36e31",
   "metadata": {},
   "source": [
    "# Datasets Ookla\n",
    "> Download ookla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d8c85d-fad5-4cf2-8a00-d99f8276e4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exporti\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import namedtuple\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Union\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import HTTPError\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from fastcore.basics import patch\n",
    "from fastcore.parallel import parallel\n",
    "from loguru import logger\n",
    "\n",
    "import geowrangler.area_zonal_stats as azs\n",
    "from geowrangler import grids\n",
    "from geowrangler.datasets.utils import make_report_hook, urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a68395-fcaa-4114-87b2-a5f05f5356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "OoklaFile = namedtuple(\"OoklaQuarter\", [\"type\", \"year\", \"quarter\"])\n",
    "DEFAULT_CACHE_DIR = \"~/.cache/geowrangler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a30a6d-c28d-4be2-9325-ac7618d49a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@lru_cache(maxsize=None)\n",
    "def list_ookla_files() -> dict:\n",
    "    \"\"\"Get list of ookla data\"\"\"\n",
    "    # Query parquet files as they are easier to deal with then shapefiles\n",
    "    resp = requests.get(\n",
    "        \"https://ookla-open-data.s3.us-west-2.amazonaws.com/?list-type=2&prefix=parquet\"\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    root = ET.fromstring(resp.text)\n",
    "    keys = {}\n",
    "    # Get keys. This would require pagination once there are more than 1000 keys under the parquet folder\n",
    "    # but that would only happen after ~125 years\n",
    "    for child in root.findall(\"{http://s3.amazonaws.com/doc/2006-03-01/}Contents\"):\n",
    "        key = child.find(\"{http://s3.amazonaws.com/doc/2006-03-01/}Key\").text\n",
    "        path_key = Path(key)\n",
    "        type_ = path_key.parts[2].rsplit(\"=\")[-1]\n",
    "        year = path_key.parts[3].rsplit(\"=\")[-1]\n",
    "        quarter = path_key.parts[4].rsplit(\"=\")[-1]\n",
    "        file = path_key.parts[5]\n",
    "        keys.update({OoklaFile(type_, year, quarter): file})\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fde158e-98ef-43a1-836b-fed81205d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_ookla_file(\n",
    "    type_: str,  # Internet connection type: 'fixed' or 'mobile'\n",
    "    year: str,  # Year (e.g. '2020')\n",
    "    quarter: str,  # Quarter (valid values: '1','2','3','4')\n",
    "    directory: str = \"data/\",  # Download directory\n",
    "    overwrite: bool = False,  # Overwrite if existing\n",
    ") -> List[Path]:\n",
    "    \"\"\"Download ookla file to path\"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    ookla_info = list_ookla_files()\n",
    "    key = OoklaFile(type_, str(year), str(quarter))\n",
    "    if key not in ookla_info:\n",
    "        raise ValueError(\n",
    "            f\"{key} not found in ookla. Run list_ookla_data() to learn more about available files\"\n",
    "        )\n",
    "    file = ookla_info[key]\n",
    "    url = f\"https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type={type_}/year={year}/quarter={quarter}/{file}\"\n",
    "    parsed_url = urlparse(url)\n",
    "    filename = Path(os.path.basename(parsed_url.path))\n",
    "    filepath = directory / filename\n",
    "    if not filepath.exists() or overwrite:\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(filepath, \"wb\") as out_file:\n",
    "            shutil.copyfileobj(response.raw, out_file)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c76533-3a3a-4dec-b98e-d0cbdcd26b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_OoklaFile(filename):\n",
    "    \"\"\"Get the corresponding OoklaFile tuple given the filename\n",
    "    See: https://stackoverflow.com/questions/8023306/get-key-by-value-in-dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    available_ookla_files = list_ookla_files()\n",
    "    for ooklafile_tuple, ooklafile_item in available_ookla_files.items():\n",
    "        if ooklafile_item == filename:\n",
    "            return ooklafile_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6154b68d-331f-4bd5-a144-7219980433f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def compute_datakey(aoi_bounds, type_, year, return_geometry):\n",
    "    data_tuple = (\n",
    "        np.array2string(aoi_bounds, precision=6),\n",
    "        str(type_),\n",
    "        str(year),\n",
    "        str(return_geometry),\n",
    "    )\n",
    "    m = hashlib.md5()\n",
    "    for item in data_tuple:\n",
    "        m.update(item.encode())\n",
    "    data_key = m.hexdigest()\n",
    "    return data_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b69fc5-2d54-48af-a9ff-61afe535ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_ookla_metajson(\n",
    "    cache_dir, data_key, total_bounds, type_, year, return_geometry\n",
    "):\n",
    "    cached_metajson_file_path = (\n",
    "        os.path.join(cache_dir, f\"{data_key}.geojson.metadata.json\")\n",
    "        if return_geometry\n",
    "        else os.path.join(cache_dir, f\"{data_key}.csv.metadata.json\")\n",
    "    )\n",
    "    with open(cached_metajson_file_path, \"w\") as f:\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"bounds\": np.array2string(total_bounds, precision=6),\n",
    "                    \"type_\": type_,\n",
    "                    \"year\": year,\n",
    "                    \"with_geom\": return_geometry,\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c720b27-0194-4dcc-80c5-42a8bde7c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class OoklaDataManager:\n",
    "    \"\"\"An instance of this class provides convenience functoins for loading and caching Ookla data\"\"\"\n",
    "\n",
    "    def __init__(self, cache_dir=DEFAULT_CACHE_DIR):\n",
    "        self.data_cache = {}\n",
    "        self.cache_dir = os.path.expanduser(cache_dir)\n",
    "        self.processed_cache_dir = os.path.join(self.cache_dir, \"ookla/processed/\")\n",
    "        Path(self.processed_cache_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be695dbe-a999-4b6b-adc7-98b2837a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def reinitialize_processed_cache(self: OoklaDataManager):\n",
    "    \"Reinitialize processed_cache_dir to start over from scratch.\"\n",
    "    shutil.rmtree(self.processed_cache_dir, ignore_errors=True)\n",
    "    response = Path(self.processed_cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(\n",
    "        f\"{self.processed_cache_dir} reintialized. All cached processed data in this folder has been deleted.\"\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ddb416-74c9-4579-9792-ea269ce19ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def load_type_year_data(\n",
    "    self: OoklaDataManager, aoi, type_, year, use_cache=True, return_geometry=False\n",
    "):\n",
    "    \"Load Ookla data across all quarters for a specified aoi, type (fixed, mobile) and year\"\n",
    "\n",
    "    # Generate hash from aoi, type_, and year, which will act as a hash key for the cache\n",
    "    data_key = compute_datakey(aoi.total_bounds, type_, year, return_geometry)\n",
    "    # Get from RAM cache if already available\n",
    "    logger.debug(f\"Contents of data cache: {list(self.data_cache.keys())}\")\n",
    "    if data_key in self.data_cache:\n",
    "        logger.debug(\n",
    "            f\"Ookla data for aoi, {type_} {year} (key: {data_key}) found in cache.\"\n",
    "        )\n",
    "        return self.data_cache[data_key]\n",
    "\n",
    "    ## Get cached data from filesystem if saved\n",
    "    cached_file_path = (\n",
    "        os.path.join(self.processed_cache_dir, f\"{data_key}.geojson\")\n",
    "        if return_geometry\n",
    "        else os.path.join(self.processed_cache_dir, f\"{data_key}.csv\")\n",
    "    )\n",
    "\n",
    "    cached_data_available = os.path.exists(cached_file_path)\n",
    "    logger.info(f\"Cached data available at {cached_file_path}? {cached_data_available}\")\n",
    "\n",
    "    if cached_data_available:\n",
    "        logger.debug(\n",
    "            f\"Processed Ookla data for aoi, {type_} {year} (key: {data_key}) found in filesystem. Loading in cache.\"\n",
    "        )\n",
    "        if not return_geometry:\n",
    "            df = pd.read_csv(cached_file_path)\n",
    "            self.data_cache[data_key] = df\n",
    "            return df\n",
    "        else:\n",
    "            gdf = gpd.read_file(cached_file_path, driver=\"GeoJSON\")\n",
    "            self.data_cache[data_key] = gdf\n",
    "            return gdf\n",
    "\n",
    "    logger.debug(\"No cached data found. Processing Ookla data from scratch.\")\n",
    "\n",
    "    # Otherwise, load from raw file and add to RAM cache\n",
    "    type_year_cache_dir = download_ookla_year_data(\n",
    "        type_,\n",
    "        year,\n",
    "        cache_dir=self.cache_dir,\n",
    "        use_cache=use_cache,\n",
    "    )\n",
    "\n",
    "    # Generate the bing tile quadkeys that intersect with the input aoi\n",
    "    logger.debug(\n",
    "        f\"Generating bing tile grids for aoi total bounds {np.array2string(aoi.total_bounds, precision=6)}\"\n",
    "    )\n",
    "    bing_tile_grid_generator_no_geom = grids.BingTileGridGenerator(\n",
    "        16, return_geometry=False\n",
    "    )\n",
    "    aoi_quadkeys = bing_tile_grid_generator_no_geom.generate_grid(aoi)[\n",
    "        \"quadkey\"\n",
    "    ].tolist()\n",
    "\n",
    "    # Combine quarterly data for the specified year, filtered to the aoi using quadkey\n",
    "    # Quarter is inferred from the Ookla filename\n",
    "    quarter_df_list = []\n",
    "    for ookla_filename in sorted(os.listdir(type_year_cache_dir)):\n",
    "        quarter = int(getattr(get_OoklaFile(ookla_filename), \"quarter\"))\n",
    "        ookla_quarter_filepath = os.path.join(type_year_cache_dir, ookla_filename)\n",
    "        logger.debug(\n",
    "            f\"Ookla data for aoi, {type_} {year} {quarter} being loaded from {ookla_quarter_filepath}\"\n",
    "        )\n",
    "        quarter_df = pd.read_parquet(ookla_quarter_filepath)\n",
    "        quarter_df = quarter_df[quarter_df[\"quadkey\"].isin(aoi_quadkeys)]\n",
    "        quarter_df[\"quarter\"] = quarter\n",
    "        quarter_df_list.append(quarter_df)\n",
    "\n",
    "        # Free memory after processing\n",
    "        del quarter_df\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Concatenating quarterly Ookla data for {type_} and {year} into one dataframe\"\n",
    "    )\n",
    "    df = pd.concat(quarter_df_list, ignore_index=True)\n",
    "\n",
    "    # NOTE: Since there will be groupby operations in processing, we don't return\n",
    "    #       a geodataframe by default since it does not work well with aggregations\n",
    "    #       by quadkey.\n",
    "    write_ookla_metajson(\n",
    "        self.processed_cache_dir,\n",
    "        data_key,\n",
    "        aoi.total_bounds,\n",
    "        type_,\n",
    "        year,\n",
    "        return_geometry,\n",
    "    )\n",
    "\n",
    "    if not return_geometry:\n",
    "        logger.debug(f\"Saving Ookla data into csv file {cached_file_path}\")\n",
    "        self.data_cache[data_key] = df\n",
    "        df.to_csv(cached_file_path, index=False)\n",
    "        return df\n",
    "    else:\n",
    "        logger.debug(f\"Converting Ookla data into geojson file {cached_file_path}\")\n",
    "        gdf = gpd.GeoDataFrame(df, geometry=gpd.GeoSeries.from_wkt(df[\"tile\"]))\n",
    "        self.data_cache[data_key] = gdf\n",
    "        logger.debug(f\"Saving Ookla data into geojson file {cached_file_path}\")\n",
    "        gdf.to_file(cached_file_path, driver=\"GeoJSON\")\n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4865876c-69aa-4d51-adf4-734d298d20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_ookla_file(\n",
    "    type_: str,  # Internet connection type: 'fixed' or 'mobile'\n",
    "    year: str,  # Year (e.g. '2020')\n",
    "    quarter: str,  # Quarter (valid values: '1','2','3','4')\n",
    "    directory: str = \"data/\",  # Download directory\n",
    "    overwrite: bool = False,  # Overwrite if existing\n",
    "    show_progress=True,  # show progres bar\n",
    "    chunksize=8192,  # Download chunksize\n",
    "    reporthook=None,  # Use custom progress bar\n",
    ") -> Union[Path, None]:\n",
    "    \"\"\"Download ookla file to path\"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    ookla_info = list_ookla_files()\n",
    "    key = OoklaFile(type_, str(year), str(quarter))\n",
    "    if key not in ookla_info:\n",
    "        raise ValueError(\n",
    "            f\"{key} not found in ookla. Run list_ookla_data() to learn more about available files\"\n",
    "        )\n",
    "    fname = ookla_info[key]\n",
    "    url = f\"https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type={type_}/year={year}/quarter={quarter}/{fname}\"\n",
    "    parsed_url = urlparse(url)\n",
    "    filename = Path(os.path.basename(parsed_url.path))\n",
    "    filepath = directory / filename\n",
    "    if not filepath.exists() or overwrite:\n",
    "        if reporthook is None:\n",
    "            reporthook = make_report_hook(show_progress)\n",
    "\n",
    "        try:\n",
    "            filepath, _, _ = urlretrieve(\n",
    "                url, filepath, reporthook=reporthook, chunksize=chunksize\n",
    "            )\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404:\n",
    "                logger.warning(\n",
    "                    f\"No url found for type {type_} year {year} and {quarter} : {url} \"\n",
    "                )\n",
    "                return None\n",
    "            else:\n",
    "                raise err\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c612bfab-4246-4b20-a44e-8e8efcae2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def parallel_download(item):\n",
    "    quarter, type_, year, directory = item  # unpack tuple\n",
    "    logger.info(\n",
    "        f\"Ookla Data: Downloading Ookla parquet file for quarter {quarter}... type: {type_} year: {year} in {directory}\"\n",
    "    )\n",
    "    return download_ookla_file(\n",
    "        type_=type_,\n",
    "        year=year,\n",
    "        quarter=quarter,\n",
    "        directory=directory,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42707bb-ee16-4666-a7cd-6877aea4ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def download_ookla_parallel(num_expected_ookla_files, type_, year, directory):\n",
    "    items = [\n",
    "        (str(i), type_, year, directory)\n",
    "        for i in range(1, num_expected_ookla_files + 1, 1)\n",
    "    ]\n",
    "    parallel(parallel_download, items, threadpool=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14bb3c79-5d97-42a9-8457-046dd2b407b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def download_ookla_year_data(type_, year, cache_dir, use_cache=True):\n",
    "\n",
    "    \"Download ookla data for a specifed type (fixed or mobile) and year. Data for all 4 quarters will be downloaded.\"\n",
    "\n",
    "    # Determine number of expected data for type_ and year, specified by OoklaFile(type, year, quarter)\n",
    "    available_ookla_files = list_ookla_files()\n",
    "    expected_ookla_files = {}\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        quarter_ookla_file = OoklaFile(str(type_), str(year), str(quarter))\n",
    "        if quarter_ookla_file in available_ookla_files.keys():\n",
    "            expected_ookla_files[quarter_ookla_file] = available_ookla_files[\n",
    "                quarter_ookla_file\n",
    "            ]\n",
    "    num_expected_ookla_files = len(expected_ookla_files)\n",
    "\n",
    "    if num_expected_ookla_files == 0:\n",
    "        logger.warning(f\"Ookla data: No data available for {type_} and {year}\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Number of available files for {type_} and {year}: {num_expected_ookla_files}\"\n",
    "        )\n",
    "\n",
    "    ookla_cache_dir = os.path.join(cache_dir, \"ookla/\")\n",
    "    type_year_cache_dir = os.path.join(ookla_cache_dir, type_, str(year))\n",
    "\n",
    "    # Check if the cached data is valid. Otherwise, we have to re-download.\n",
    "    # For Ookla, we need to check if we've downloaded all expected files for that year.\n",
    "    cached_data_available = (\n",
    "        os.path.exists(type_year_cache_dir)\n",
    "        and len(os.listdir(type_year_cache_dir)) == num_expected_ookla_files\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Ookla Data: Cached data available for {type_} and {year} at {type_year_cache_dir}? {cached_data_available}\"\n",
    "    )\n",
    "\n",
    "    # Download if cache is invalid or user specified use_cache = False\n",
    "    if not cached_data_available or not use_cache:\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Re-initializing Ookla type/year cache dir at {type_year_cache_dir}...\"\n",
    "        )\n",
    "        # Re-create the country cache dir and start over to fix any corrupted states\n",
    "        shutil.rmtree(type_year_cache_dir, ignore_errors=True)\n",
    "        Path(type_year_cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # This downloads a parquet file to the type_year_dir for each quarter\n",
    "        download_ookla_parallel(\n",
    "            num_expected_ookla_files, type_, year, type_year_cache_dir\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Successfully downloaded and cached Ookla data for {type_} and {year} at {type_year_cache_dir}!\"\n",
    "        )\n",
    "\n",
    "    return type_year_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75432dda-099d-4aa1-b593-6a17303a124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def add_ookla_features(\n",
    "    aoi: gpd.GeoDataFrame,  # Area of interest\n",
    "    type_: str,  # Ookla speed type: 'fixed` or `mobile`\n",
    "    year: str,  # Year to aggregate (over 4 quarters)\n",
    "    ookla_data_manager: OoklaDataManager,  # Ookla Data Manager Instance\n",
    "    use_cache=True,  # Use cached data in cache dir as specified in ookla_data_manager\n",
    "    metric_crs=\"epsg:3123\",  # metric crs to use in calculating overlap\n",
    "    inplace=False,  # Modify original aoi\n",
    "    aggregations: Dict[  # Aggregation functions on ookla data (see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html)\n",
    "        str, Any\n",
    "    ] = dict(\n",
    "        mean_avg_d_kbps=(\"avg_d_kbps\", \"mean\"),\n",
    "        mean_avg_u_kbps=(\"avg_u_kbps\", \"mean\"),\n",
    "        mean_avg_lat_ms=(\"avg_lat_ms\", \"mean\"),\n",
    "        mean_num_tests=(\"tests\", \"mean\"),\n",
    "        mean_num_devices=(\"devices\", \"mean\"),\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Generates yearly aggregate features for the AOI based on Ookla data for a given type (fixed, mobile) and year.\"\"\"\n",
    "\n",
    "    ookla = ookla_data_manager.load_type_year_data(\n",
    "        aoi, type_, year, use_cache=use_cache\n",
    "    )\n",
    "\n",
    "    # Create a copy of the AOI gdf if not inplace to avoid modifying the original gdf\n",
    "    if not inplace:\n",
    "        aoi = aoi.copy()\n",
    "\n",
    "    # Combine quarterly data from Ookla into yearly aggregate data\n",
    "    # Geometries are stored separately and rejoined after aggregation by quadkey\n",
    "    # TODO: incorporate parametrized aggregations, take inspiration from GeoWrangler agg spec\n",
    "\n",
    "    logger.info(\n",
    "        f\"Aggregating ookla data for bounds {np.array2string(aoi.total_bounds, precision=6)} type {type_} year {year} \"\n",
    "    )\n",
    "    ookla_geoms = ookla[[\"quadkey\", \"tile\"]].drop_duplicates().reset_index(drop=True)\n",
    "    ookla_yearly = ookla.groupby(\"quadkey\").agg(**aggregations).reset_index()\n",
    "    # Add type_year prefix to feature names\n",
    "    ookla_yearly = ookla_yearly.rename(\n",
    "        {\n",
    "            col: f\"{type_}_{year}_\" + col\n",
    "            for col in ookla_yearly.columns[~ookla_yearly.columns.isin([\"quadkey\"])]\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    ookla_yearly = ookla_yearly.merge(ookla_geoms, on=\"quadkey\", how=\"left\")\n",
    "    ookla_yearly = gpd.GeoDataFrame(\n",
    "        ookla_yearly,\n",
    "        geometry=gpd.GeoSeries.from_wkt(ookla_yearly[\"tile\"], crs=\"epsg:4326\"),\n",
    "    )\n",
    "\n",
    "    # GeoWrangler: area zonal stats of features per AOI\n",
    "    features = ookla_yearly.columns[\n",
    "        ~ookla_yearly.columns.isin([\"quadkey\", \"tile\", \"geometry\"])\n",
    "    ]\n",
    "    agg_funcs = [\"mean\"]\n",
    "    feature_aggregrations = [\n",
    "        dict(func=agg_funcs, column=feature) for feature in features\n",
    "    ]\n",
    "    logger.info(\n",
    "        f\"Creating ookla zonal stats for bounds {np.array2string(aoi.total_bounds, precision=6)} type {type_} year {year} \"\n",
    "    )\n",
    "    aoi_orig_crs = aoi.crs\n",
    "    aoi = azs.create_area_zonal_stats(\n",
    "        aoi.to_crs(metric_crs),\n",
    "        ookla_yearly.to_crs(metric_crs),\n",
    "        feature_aggregrations,\n",
    "        include_intersect=False,\n",
    "    ).to_crs(aoi_orig_crs)\n",
    "\n",
    "    return aoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d8b707-6b41-426b-9135-a422d5a2ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05_datasets_ookla.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# no_test\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script(\"05_datasets_ookla.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a07a05096b6351e45107f092fcbc6d58e4d1183d490a1128ce24e8ca5af3ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
